{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(101)\n",
    "\n",
    "# Simulate data\n",
    "n_samples = 10000\n",
    "\n",
    "# Features\n",
    "x1 = np.linspace(0, 10, n_samples)\n",
    "x2 = np.random.uniform(-2, 2, n_samples)\n",
    "\n",
    "# Additional features\n",
    "x3 = np.random.normal(0, 1, n_samples)  # Normally distributed feature\n",
    "x4 = np.random.beta(2, 5, n_samples)  # Feature with a beta distribution\n",
    "x5 = np.random.choice([0, 1, 2, 3], size=n_samples)  # cat feature\n",
    "\n",
    "# Updated target variable with more complex relationships\n",
    "y = (\n",
    "    3 * np.sin(x1) - 1.5 * np.cos(x2) +  # Sinusoidal and cosinusoidal relationships\n",
    "    2 * np.square(x3) - x4**3 +  # Squared and cubic functions\n",
    "    3 * x5 +  # Influence of the binary feature\n",
    "    0.2 * x1 * x3 + 0.1 * x2 * x4 - 0.5 * x3 * x5 +  # Feature interactions\n",
    "    np.random.normal(0, 1, n_samples)  # Noise\n",
    ")\n",
    "\n",
    "y = y/np.max(y)\n",
    "# Update the DataFrame with the new features\n",
    "data = pd.DataFrame({\n",
    "    'x1': x1,\n",
    "    'x2': x2,\n",
    "    'x3': x3,\n",
    "    'x4': x4,\n",
    "    'x5': x5,\n",
    "    'y': y\n",
    "})\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nampy.models import NAMLSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "namlss = NAMLSS(\n",
    "    \"y ~ -1 + MLP(x1; Dropout=0.1) + MLP(x2) + MLP(x3) + MLP(x4) + MLP(x5)\",   \n",
    "    data=data, \n",
    "    feature_dropout=0.0001,\n",
    "    family=\"Normal\",\n",
    "    loss=\"nll\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "namlss.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "    loss={\"output\":namlss.Loss}, \n",
    "    )\n",
    "\n",
    "# Train the model\n",
    "namlss.fit(namlss.training_dataset, epochs=150, validation_data=namlss.validation_dataset)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = namlss.evaluate(namlss.validation_dataset)\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namlss.plot_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xDl_venv",
   "language": "python",
   "name": "xdl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
